{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transfer learning with keras (tenorflow backend)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#first we will import some libraries, functions.\n",
    "#we will be using Vgg16 architecture, feel free to use any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import model_from_yaml\n",
    "from keras import models, layers, optimizers\n",
    "from keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we will be using only the convolution part of the model, so we will keep include_top = False, for using the whole model as such use include_top = True. input shape will be the dimensions of the image on the model was trained. weights will be of imagenet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = VGG16(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#provide the path for training and validation path. the directory should contain other sub-directories #belonging to their specific classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r'path_do_training_directory'\n",
    "validation_dir = r'path_do_validation_directory'\n",
    "\n",
    "batch_size = 20\n",
    "n_classes = 'no_of_classes_to_train_for'\n",
    "n_train = 'no_of_training_images'\n",
    "n_valid = 'no_of_validation_images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create a data generator to flow the data from directory to the conv_base for both training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale = 1./255)\n",
    "train_features = np.zeros(shape = (n_train, 7, 7, 512))\n",
    "train_labels = np.zeros(shape = (n_train, n_classes))\n",
    "\n",
    "train_generator = datagen.flow_from_directory(train_dir,\n",
    "                                             target_size = (224, 224),\n",
    "                                             batch_size = batch_size,\n",
    "                                             class_mode = 'categorical',\n",
    "                                             shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for inputs_batch, labels_batch in train_generator:\n",
    "    features_batch = conv_base.predict(inputs_batch)\n",
    "    train_features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "    train_labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "    i += 1\n",
    "    if i * batch_size >= n_train:\n",
    "        break\n",
    "         \n",
    "train_features = np.reshape(train_features, (n_train, 7 * 7 * 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating our own fully connected neural network to do the classification, using keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(units = 256, activation = 'relu', input_dim = 7*7*512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(2, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training our fully connected network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.RMSprop(lr=2e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    " \n",
    "history = model.fit(train_features,\n",
    "                    train_labels,\n",
    "                    epochs = 20,\n",
    "                    batch_size = batch_size,\n",
    "                    validation_data = (validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to YAML\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"model.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for loading the model to memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file = open('model.yaml', 'r')\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "loaded_model = model_from_yaml(loaded_model_yaml)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "# use loaded_model to compile,fit etc.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to check the misclassified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = train_generator_valid.filenames\n",
    " \n",
    "ground_truth = train_generator_valid.classes\n",
    " \n",
    "label2index = train_generator_valid.class_indices\n",
    " \n",
    "# Getting the mapping from class index to class label\n",
    "idx2label = dict((v,k) for k,v in label2index.items())\n",
    " \n",
    "predictions = model.predict_classes(validation_features)\n",
    "prob = model.predict(validation_features)\n",
    " \n",
    "errors = np.where(predictions != ground_truth)[0]\n",
    "print(\"No of errors = {}/{}\".format(len(errors),n_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(errors)):\n",
    "    pred_class = np.argmax(prob[errors[i]])\n",
    "    pred_label = idx2label[pred_class]\n",
    "     \n",
    "    print('Original label:{}, Prediction :{}, confidence : {:.3f}'.format(\n",
    "        fnames[errors[i]].split('/')[0],\n",
    "        pred_label,\n",
    "        prob[errors[i]][pred_class]))\n",
    "     \n",
    "    original = Image.open('{}/{}'.format(validation_dir,fnames[errors[i]]))\n",
    "    plt.imshow(original)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
